{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "title": "Canopy Backend Helm Chart Values Schema",
  "description": "Schema for validating values.yaml configuration for the Canopy Backend Helm chart",
  "properties": {
    "LLAMA_STACK_URL": {
      "type": "string",
      "description": "Base URL for the LLaMA Stack service",
      "pattern": "^https?://[^\\s]+$",
      "examples": [
        "http://llama-stack",
        "http://llama-stack:8000",
        "https://my-llama-service.example.com"
      ]
    },
    "summarize": {
      "type": "object",
      "description": "Configuration for summarization functionality",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable or disable summarization functionality",
          "default": false
        },
        "model": {
          "type": "string",
          "description": "Model identifier to use for summarization",
          "minLength": 1,
          "examples": [
            "llama32",
            "llama3.2",
            "gpt-4"
          ]
        },
        "prompt": {
          "type": "string",
          "description": "Prompt template for summarization requests",
          "minLength": 1
        },
        "max_tokens": {
          "type": "number",
          "description": "Max tokens for the model"
        },
        "temperature": {
          "type": "number",
          "description": "Temperature for the model"
        }
      },
      "required": ["enabled", "model", "prompt"],
      "additionalProperties": false
    },
    "information-search": {
      "type": "object",
      "description": "Configuration for information search functionality",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable or disable information search functionality",
          "default": false
        },
        "model": {
          "type": "string",
          "description": "Model identifier to use for information search",
          "minLength": 1,
          "examples": [
            "llama32",
            "llama3.2",
            "gpt-4"
          ]
        },
        "prompt": {
          "type": "string",
          "description": "System prompt for information search requests",
          "minLength": 1
        },
        "max_tokens": {
          "type": "number",
          "description": "Max tokens for the model"
        },
        "temperature": {
          "type": "number",
          "description": "Temperature for the model"
        },
        "chart_path": {
          "type": "string",
          "description": "Target namespace for deployment (format: userX-environment)",
          "examples": []
        },
        "repo_url": {
          "type": "string",
          "description": "Repository URL for the Helm chart",
          "examples": []
        }
      },
      "required": ["enabled", "model", "prompt"],
      "additionalProperties": false
    }
  },
  "required": ["LLAMA_STACK_URL"],
  "additionalProperties": false
}